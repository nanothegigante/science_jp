# 科学技術白書（PDF版）コーパス構築および分布意味分析パイプライン

本リポジトリでは、2017〜2025年の『科学技術白書（科学技術・イノベーション白書）』PDF版を対象に、テキストコーパスを構築し、「科学」という語の分布意味的特徴を分析するための処理手順を整理する。

本ドキュメントでは、以下の工程について記録する。

1. データ収集（PDF版のみ）
2. PDFからテキスト抽出
3. テキスト前処理
4. 形態素解析（SudachiPy）
5. Word2Vecによる分布意味分析
6. 近傍語抽出

HTML版の収集・処理については本プロジェクトでは扱わない。（WARPに格納された過去のHTML版科学技術白書についても、同様の分析が行えるように改良を進める予定。）

---

## 1. データ収集

### 対象
- 科学技術白書（2017年〜2025年）
- PDF版のみ使用

### ディレクトリ構造

```text
corpus/
  pdf/
    2017_h29/
      *.pdf
    2018_h30/
      *.pdf
    2019_r1/
      *.pdf
    ...
```

各年ごとにフォルダを分け、その中に複数PDF（本文）を格納した。特集記事や寄稿記事なども収集の対象としたが、ひとつ2025年の付録記事である『白書のテキストマイニングによる政策動向分析』についてのみ、白書の内容をメタに見るという、本分析の志すところと同じ視点であるという理由から、収集対象から除外した。

---

## 2. PDFからテキスト抽出

### 使用ライブラリ
- `PyMuPDF（fitz）`

### 目的
- PDFレイアウトを考慮しつつテキストを抽出
- 1カラム／2カラム文書の双方に対応
- 年ごとに統合テキストを生成

### 出力構造

```text
txt_raw/
  2017.txt
  2018.txt
  ...
```

### 特徴
- ページ単位でテキストブロックを取得
- 座標情報に基づき読み順を調整
- 1カラム／2カラムを自動判定
- 年ごとにPDFを統合

---

## 3. テキスト前処理

### 目的
- 図表由来ノイズの削減
- 不要行の削除
- 改行の整理（完全除去は行わない）

## 実施内容
- 数字・記号比率が極端に高い行の除去
- 「図」「表」「出典」などのキャプション除去
- 連続空白の圧縮

### 出力
``` text
txt_clean/
  2017.clean.txt
  2018.clean.txt
  ...
```

---

## 4. 形態素解析

### 使用ライブラリ
- `SudachiPy`
- `sudachidict_core`

### 目的
- 白書テキストをトークン列へ変換
- Word2Vec入力形式へ整列

### 課題と対応
`SudachiPy`には入力バイト数制限（約49KB）があるため、
- 段落単位でテキストを分割
- 分割後に逐次トークン化
- ストリーミング出力
を行った。

### 出力
```text
tokens/
  2017.tokens.txt
  2018.tokens.txt
  ...
```

### トークン数（参考）
```text
2017: 200,534
2018: 174,026
2019: 136,827
2020: 149,978
2021: 135,119
2022: 138,771
2023: 121,427
2024: 153,096
2025: 151,151
```
全体で約136万トークン。

---






